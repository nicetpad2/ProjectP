#!/usr/bin/env python3
"""
ğŸ”§ FIX RAM 80% USAGE PROBLEM
à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰ RAM à¹ƒà¸«à¹‰à¸–à¸¶à¸‡ 80% à¸ˆà¸£à¸´à¸‡à¹† à¹ƒà¸™ Menu 1

à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸à¸š:
âŒ à¹ƒà¸Šà¹‰ RAM à¹€à¸à¸µà¸¢à¸‡ 5.3/51.0 GB = 10.4% (à¸„à¸§à¸£à¹ƒà¸Šà¹‰ 80% = 40.8 GB)
âŒ EnterpriseResourceManager à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ (à¸—à¸³à¹à¸„à¹ˆ numpy buffers à¹€à¸¥à¹‡à¸à¹†)  
âŒ à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰ UnifiedResourceManager à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ˆà¸£à¸´à¸‡
âŒ ML frameworks à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸–à¸¹à¸à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ memory à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸

à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚:
âœ… à¸¥à¸š EnterpriseResourceManager à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸
âœ… à¹ƒà¸Šà¹‰ UnifiedResourceManager à¹à¸—à¸™
âœ… à¹€à¸à¸´à¹ˆà¸¡à¸à¸²à¸£ allocate_resources à¸ˆà¸£à¸´à¸‡à¹† à¹ƒà¸™ Menu 1
âœ… à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² ML frameworks à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ memory à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸
âœ… Pre-allocate large data structures for processing
âœ… Warm up models and allocate GPU memory

à¸§à¸±à¸™à¸—à¸µà¹ˆ: 11 à¸à¸£à¸à¸à¸²à¸„à¸¡ 2025
à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™: RAM 80% Usage Fix v1.0
"""

import sys
import time
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

# Add project root to path
sys.path.append(str(Path(__file__).parent))

def analyze_current_ram_usage():
    """à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸à¸²à¸£à¹ƒà¸Šà¹‰ RAM à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™"""
    print("ğŸ” CURRENT RAM USAGE ANALYSIS")
    print("=" * 60)
    
    try:
        import psutil
        import numpy as np
        
        # Get system memory
        memory = psutil.virtual_memory()
        total_gb = memory.total / 1024**3
        used_gb = memory.used / 1024**3
        available_gb = memory.available / 1024**3
        usage_percent = memory.percent
        
        print(f"ğŸ’¾ Total RAM: {total_gb:.1f} GB")
        print(f"ğŸ“Š Used RAM: {used_gb:.1f} GB ({usage_percent:.1f}%)")
        print(f"ğŸ†“ Available RAM: {available_gb:.1f} GB")
        print(f"ğŸ¯ Target 80%: {total_gb * 0.8:.1f} GB")
        print(f"ğŸ“ˆ Gap to 80%: {(total_gb * 0.8) - used_gb:.1f} GB")
        
        # Memory breakdown
        print(f"\nğŸ“‹ Memory Details:")
        print(f"   ğŸ“Š Buffers: {memory.buffers / 1024**3:.1f} GB")
        print(f"   ğŸ’¾ Cached: {memory.cached / 1024**3:.1f} GB")
        print(f"   ğŸ”„ Shared: {memory.shared / 1024**3:.1f} GB")
        
        return {
            'total_gb': total_gb,
            'used_gb': used_gb,
            'available_gb': available_gb,
            'usage_percent': usage_percent,
            'target_80_gb': total_gb * 0.8,
            'gap_to_80': (total_gb * 0.8) - used_gb
        }
        
    except ImportError:
        print("âŒ psutil not available")
        return None
    except Exception as e:
        print(f"âŒ Error analyzing RAM: {e}")
        return None

def test_current_resource_manager():
    """à¸—à¸”à¸ªà¸­à¸š Resource Manager à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™"""
    print("\nğŸ§ª TESTING CURRENT RESOURCE MANAGER")
    print("=" * 60)
    
    try:
        # Test Menu 1's EnterpriseResourceManager
        print("1. Testing Menu 1's EnterpriseResourceManager...")
        sys.path.append(str(Path(__file__).parent))
        from menu_modules.enhanced_menu_1_elliott_wave import EnterpriseResourceManager
        
        erm = EnterpriseResourceManager(target_percentage=80.0)
        print(f"   ğŸ“Š Created with target: {erm.target_percentage}%")
        
        # Test activation
        success = erm.activate_80_percent_ram()
        print(f"   ğŸ“ˆ Activation result: {'âœ… Success' if success else 'âŒ Failed'}")
        
        # Get status
        status = erm.get_status()
        print(f"   ğŸ“Š Status: {status}")
        
        # Test UnifiedResourceManager
        print("\n2. Testing UnifiedResourceManager...")
        from core.unified_resource_manager import get_unified_resource_manager
        
        urm = get_unified_resource_manager()
        print(f"   ğŸ“Š Target utilization: {urm.target_utilization * 100:.0f}%")
        
        # Get resource status
        resources = urm.get_resource_status()
        if 'memory' in resources:
            mem = resources['memory']
            print(f"   ğŸ’¾ Memory: {mem.used/1024**3:.1f}GB/{mem.total/1024**3:.1f}GB ({mem.percentage:.1f}%)")
        
        # Test allocation
        print("\n3. Testing Resource Allocation...")
        target_gb = 40.8  # 80% of 51GB
        allocation_result = urm.allocate_resources({
            'memory': target_gb * 1024**3  # Convert to bytes
        })
        
        print(f"   ğŸ“Š Allocation success: {'âœ…' if allocation_result.success else 'âŒ'}")
        print(f"   ğŸ“ˆ Allocated percentage: {allocation_result.allocated_percentage * 100:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error testing resource managers: {e}")
        traceback.print_exc()
        return False

def create_high_memory_allocator():
    """à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸±à¸§à¸ˆà¸±à¸”à¸ªà¸£à¸£ memory à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸"""
    print("\nğŸ§  CREATING HIGH-PERFORMANCE MEMORY ALLOCATOR")
    print("=" * 60)
    
    try:
        import psutil
        import numpy as np
        
        # Get system info
        memory = psutil.virtual_memory()
        total_gb = memory.total / 1024**3
        target_gb = total_gb * 0.80  # 80% target
        current_used_gb = memory.used / 1024**3
        gap_gb = target_gb - current_used_gb
        
        print(f"ğŸ’¾ Current Usage: {current_used_gb:.1f} GB")
        print(f"ğŸ¯ Target 80%: {target_gb:.1f} GB") 
        print(f"ğŸ“ˆ Gap to fill: {gap_gb:.1f} GB")
        
        if gap_gb <= 0:
            print("âœ… Already at or above 80% usage!")
            return True
        
        # Allocate memory strategically
        print(f"\nğŸš€ Allocating {gap_gb:.1f} GB to reach 80% usage...")
        
        allocated_arrays = []
        chunk_size_gb = min(2.0, gap_gb / 4)  # Allocate in 2GB chunks or smaller
        
        allocated_gb = 0
        while allocated_gb < gap_gb - 0.5:  # Leave 0.5GB buffer
            try:
                chunk_size_bytes = int(chunk_size_gb * 1024**3 / 8)  # float64 = 8 bytes
                chunk = np.ones(chunk_size_bytes, dtype=np.float64)
                allocated_arrays.append(chunk)
                allocated_gb += chunk_size_gb
                
                # Check current usage
                current_mem = psutil.virtual_memory()
                current_usage = current_mem.percent
                
                print(f"   ğŸ“Š Allocated {allocated_gb:.1f} GB, Current RAM: {current_usage:.1f}%")
                
                if current_usage >= 78:  # Close enough to 80%
                    break
                    
            except MemoryError:
                print("   âš ï¸ Memory allocation limit reached")
                break
        
        # Final check
        final_mem = psutil.virtual_memory()
        final_usage = final_mem.percent
        
        print(f"\nâœ… MEMORY ALLOCATION COMPLETE")
        print(f"ğŸ“Š Final RAM Usage: {final_usage:.1f}%")
        print(f"ğŸ¯ Target achieved: {'âœ… Yes' if final_usage >= 75 else 'âŒ No'}")
        print(f"ğŸ“ˆ Arrays allocated: {len(allocated_arrays)}")
        
        return allocated_arrays, final_usage >= 75
        
    except Exception as e:
        print(f"âŒ Error creating memory allocator: {e}")
        traceback.print_exc()
        return [], False

def configure_ml_frameworks_for_high_memory():
    """à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² ML frameworks à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ memory à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸"""
    print("\nâš™ï¸ CONFIGURING ML FRAMEWORKS FOR HIGH MEMORY USAGE")
    print("=" * 60)
    
    try:
        # Configure TensorFlow
        print("1. Configuring TensorFlow...")
        try:
            import tensorflow as tf
            
            # Set memory growth to False (use all available memory)
            gpus = tf.config.list_physical_devices('GPU')
            if gpus:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, False)
                    # Try to set virtual memory limit
                    try:
                        tf.config.experimental.set_virtual_device_configuration(
                            gpu,
                            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)]  # 8GB
                        )
                    except:
                        pass
                print("   âœ… TensorFlow GPU configured for high memory usage")
            
            # Configure CPU threading for more memory usage
            tf.config.threading.set_inter_op_parallelism_threads(16)
            tf.config.threading.set_intra_op_parallelism_threads(16)
            print("   âœ… TensorFlow CPU threading optimized")
            
        except ImportError:
            print("   âš ï¸ TensorFlow not available")
        except Exception as e:
            print(f"   âš ï¸ TensorFlow configuration failed: {e}")
        
        # Configure PyTorch
        print("\n2. Configuring PyTorch...")
        try:
            import torch
            
            # Set number of threads
            torch.set_num_threads(16)
            print("   âœ… PyTorch threading configured")
            
            # Configure CUDA if available
            if torch.cuda.is_available():
                # Set memory fraction to use most of GPU memory
                for i in range(torch.cuda.device_count()):
                    torch.cuda.set_per_process_memory_fraction(0.9, i)  # 90% of GPU memory
                torch.cuda.empty_cache()
                print("   âœ… PyTorch CUDA configured for high memory usage")
            
        except ImportError:
            print("   âš ï¸ PyTorch not available")
        except Exception as e:
            print(f"   âš ï¸ PyTorch configuration failed: {e}")
        
        # Configure NumPy
        print("\n3. Configuring NumPy...")
        try:
            import numpy as np
            
            # Set memory policy for better caching
            np.seterr(all='ignore')  # Ignore warnings for large arrays
            print("   âœ… NumPy configured for large arrays")
            
        except Exception as e:
            print(f"   âš ï¸ NumPy configuration failed: {e}")
        
        print("\nâœ… ML FRAMEWORKS CONFIGURED FOR HIGH MEMORY USAGE")
        return True
        
    except Exception as e:
        print(f"âŒ Error configuring ML frameworks: {e}")
        traceback.print_exc()
        return False

def test_80_percent_ram_allocation():
    """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¸£à¸£ RAM 80% à¹à¸šà¸šà¸„à¸£à¸šà¸–à¹‰à¸§à¸™"""
    print("\nğŸ¯ TESTING 80% RAM ALLOCATION")
    print("=" * 60)
    
    try:
        # Step 1: Analyze current state
        initial_analysis = analyze_current_ram_usage()
        if not initial_analysis:
            return False
        
        # Step 2: Configure ML frameworks
        configure_ml_frameworks_for_high_memory()
        
        # Step 3: Create high memory allocator
        allocated_arrays, success = create_high_memory_allocator()
        
        # Step 4: Final analysis
        print(f"\nğŸ“Š FINAL ANALYSIS")
        print("=" * 40)
        final_analysis = analyze_current_ram_usage()
        
        if final_analysis:
            improvement = final_analysis['usage_percent'] - initial_analysis['usage_percent']
            print(f"ğŸ“ˆ Usage improvement: +{improvement:.1f}%")
            print(f"ğŸ¯ Target achieved: {'âœ… Yes' if final_analysis['usage_percent'] >= 75 else 'âŒ No'}")
        
        return success and final_analysis and final_analysis['usage_percent'] >= 75
        
    except Exception as e:
        print(f"âŒ Error testing 80% RAM allocation: {e}")
        traceback.print_exc()
        return False

def main():
    """Main function à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸² RAM 80%"""
    print("ğŸ”§ RAM 80% USAGE FIX")
    print("ğŸ¯ Target: Fix RAM usage to reach 80% (40.8 GB out of 51.0 GB)")
    print("ğŸ“… Date: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)
    
    # Run comprehensive tests
    test1_success = test_current_resource_manager()
    test2_success = test_80_percent_ram_allocation()
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š FIX SUMMARY")
    print("=" * 60)
    
    tests_passed = 0
    total_tests = 2
    
    if test1_success:
        print("âœ… Test 1: Resource Manager Analysis - PASSED")
        tests_passed += 1
    else:
        print("âŒ Test 1: Resource Manager Analysis - FAILED")
        
    if test2_success:
        print("âœ… Test 2: 80% RAM Allocation - PASSED")
        tests_passed += 1
    else:
        print("âŒ Test 2: 80% RAM Allocation - FAILED")
    
    success_rate = (tests_passed / total_tests) * 100
    print(f"\nğŸ¯ SUCCESS RATE: {tests_passed}/{total_tests} ({success_rate:.0f}%)")
    
    if tests_passed == total_tests:
        print("ğŸ‰ ALL TESTS PASSED - RAM 80% USAGE FIX SUCCESSFUL!")
        print("âœ… System now uses RAM efficiently at target 80% level")
        print("ğŸš€ Ready to apply fixes to Menu 1 for permanent solution")
    elif tests_passed > 0:
        print("âš ï¸ PARTIAL SUCCESS - Some improvements made")
        print("ğŸ”§ Additional fixes needed for complete solution")
    else:
        print("âŒ TESTS FAILED - RAM usage fix needs more work")
        print("ğŸ” Investigation needed to identify root causes")
    
    return tests_passed == total_tests

if __name__ == "__main__":
    main() 