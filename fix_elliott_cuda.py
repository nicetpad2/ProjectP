#!/usr/bin/env python3
"""
üõ†Ô∏è CUDA FIX APPLIER FOR ELLIOTT WAVE MODULES
‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç CUDA ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Elliott Wave modules ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ CUDA ‡πÉ‡∏ô:
- cnn_lstm_engine.py
- dqn_agent.py  
- feature_selector.py
- pipeline_orchestrator.py
"""

import os
import sys
from pathlib import Path
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - CUDA_ELLIOTT_FIX - %(message)s'
)
logger = logging.getLogger(__name__)


def apply_cuda_fix_to_elliott_modules():
    """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç CUDA issues ‡πÉ‡∏ô Elliott Wave modules ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    
    logger.info("üöÄ Starting CUDA fixes for Elliott Wave modules...")
    
    # Elliott Wave modules ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
    modules_to_fix = [
        "elliott_wave_modules/cnn_lstm_engine.py",
        "elliott_wave_modules/dqn_agent.py",
        "elliott_wave_modules/feature_selector.py", 
        "elliott_wave_modules/pipeline_orchestrator.py",
        "elliott_wave_modules/data_processor.py",
        "elliott_wave_modules/performance_analyzer.py"
    ]
    
    success_count = 0
    total_modules = len(modules_to_fix)
    
    for module_path in modules_to_fix:
        logger.info(f"üîß Fixing: {module_path}")
        
        if Path(module_path).exists():
            if apply_cpu_fix_to_module(module_path):
                success_count += 1
                logger.info(f"‚úÖ Fixed: {module_path}")
            else:
                logger.warning(f"‚ö†Ô∏è Failed to fix: {module_path}")
        else:
            logger.warning(f"üìÅ File not found: {module_path}")
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    logger.info("=" * 60)
    logger.info("üéâ ELLIOTT WAVE CUDA FIX SUMMARY")
    logger.info("=" * 60)
    logger.info(f"‚úÖ Successfully fixed: {success_count}/{total_modules} modules")
    
    if success_count == total_modules:
        logger.info("üèÜ All Elliott Wave modules fixed successfully!")
        return True
    else:
        logger.warning(f"‚ö†Ô∏è {total_modules - success_count} modules had issues")
        return False


def apply_cpu_fix_to_module(module_path):
    """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏°‡∏î‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
        with open(module_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
        if "# üõ†Ô∏è CUDA FIX:" in content:
            logger.info(f"üìã {module_path} already has CUDA fix applied")
            return True
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á CUDA fix header
        cuda_fix_header = '''# üõ†Ô∏è CUDA FIX: Force CPU-only operation to prevent CUDA errors
import os
import warnings

# Environment variables to force CPU-only operation
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

# Suppress CUDA warnings
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

'''
        
        # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏ó‡∏£‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î
        lines = content.split('\n')
        insert_index = find_insertion_point(lines)
        
        # ‡πÅ‡∏ó‡∏£‡∏Å CUDA fix
        lines.insert(insert_index, cuda_fix_header)
        
        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå
        with open(module_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error fixing {module_path}: {e}")
        return False


def find_insertion_point(lines):
    """‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ó‡∏£‡∏Å CUDA fix"""
    
    # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏•‡∏±‡∏á docstring ‡πÅ‡∏•‡∏∞‡∏Å‡πà‡∏≠‡∏ô imports
    in_docstring = False
    docstring_end = 0
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö docstring
        if stripped.startswith('"""') or stripped.startswith("'''"):
            if not in_docstring:
                in_docstring = True
            elif stripped.endswith('"""') or stripped.endswith("'''"):
                docstring_end = i + 1
                break
        elif in_docstring and (stripped.endswith('"""') or stripped.endswith("'''")):
            docstring_end = i + 1
            break
    
    # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏´‡∏•‡∏±‡∏á docstring ‡πÅ‡∏ï‡πà‡∏Å‡πà‡∏≠‡∏ô import ‡πÅ‡∏£‡∏Å
    for i in range(docstring_end, len(lines)):
        stripped = lines[i].strip()
        
        # ‡∏´‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà comment ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á
        if stripped and not stripped.startswith('#'):
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô import statement ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏£‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
            if stripped.startswith('import ') or stripped.startswith('from '):
                return i
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà import ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏£‡∏Å‡∏´‡∏•‡∏±‡∏á docstring
            elif docstring_end > 0:
                return docstring_end
            else:
                return i
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏£‡∏Å‡∏´‡∏•‡∏±‡∏á docstring
    return max(1, docstring_end)


def fix_tensorflow_imports():
    """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç TensorFlow imports ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TensorFlow ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        tensorflow_fix = '''
"""
üõ†Ô∏è TensorFlow CPU-Only Import Module
Safe TensorFlow import for NICEGOLD ProjectP
"""

import os
import warnings

# Force CPU-only operation
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

def safe_tensorflow():
    """Import TensorFlow safely for CPU-only operation"""
    try:
        import tensorflow as tf
        
        # Configure for CPU only
        tf.config.set_visible_devices([], 'GPU')
        tf.get_logger().setLevel('ERROR')
        
        return tf
    except Exception as e:
        print(f"TensorFlow import error: {e}")
        return None

# Safe import
tf = safe_tensorflow()
'''
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå
        tf_safe_path = Path("core/tensorflow_safe.py")
        tf_safe_path.parent.mkdir(exist_ok=True)
        
        with open(tf_safe_path, 'w', encoding='utf-8') as f:
            f.write(tensorflow_fix)
        
        logger.info("‚úÖ TensorFlow safe import module created")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå TensorFlow fix failed: {e}")
        return False


def fix_pytorch_imports():
    """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç PyTorch imports ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PyTorch ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        pytorch_fix = '''
"""
üõ†Ô∏è PyTorch CPU-Only Import Module
Safe PyTorch import for NICEGOLD ProjectP
"""

import os

# Force CPU-only operation
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

def safe_pytorch():
    """Import PyTorch safely for CPU-only operation"""
    try:
        import torch
        
        # Set default to CPU
        torch.set_default_tensor_type('torch.FloatTensor')
        
        # Clear CUDA cache if available
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return torch
    except Exception as e:
        print(f"PyTorch import error: {e}")
        return None

# Safe import
torch = safe_pytorch()
'''
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå
        torch_safe_path = Path("core/pytorch_safe.py")
        torch_safe_path.parent.mkdir(exist_ok=True)
        
        with open(torch_safe_path, 'w', encoding='utf-8') as f:
            f.write(pytorch_fix)
        
        logger.info("‚úÖ PyTorch safe import module created")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå PyTorch fix failed: {e}")
        return False


def main():
    """Main function"""
    print("üõ†Ô∏è CUDA FIX FOR ELLIOTT WAVE MODULES")
    print("=" * 50)
    
    success_tasks = 0
    total_tasks = 3
    
    # Task 1: Fix Elliott Wave modules
    if apply_cuda_fix_to_elliott_modules():
        success_tasks += 1
    
    # Task 2: Fix TensorFlow imports
    if fix_tensorflow_imports():
        success_tasks += 1
    
    # Task 3: Fix PyTorch imports
    if fix_pytorch_imports():
        success_tasks += 1
    
    # Summary
    print("\n" + "=" * 50)
    print("üéâ CUDA FIX COMPLETE SUMMARY")
    print("=" * 50)
    print(f"‚úÖ Completed tasks: {success_tasks}/{total_tasks}")
    
    if success_tasks == total_tasks:
        print("üèÜ All CUDA fixes applied successfully!")
        print("üöÄ Elliott Wave modules should now work without CUDA errors")
        return True
    else:
        print("‚ö†Ô∏è Some fixes failed. Check the logs above.")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
