"""
üõ°Ô∏è Enterprise Risk Management System for NICEGOLD ProjectP
Advanced risk assessment, monitoring, and mitigation for financial trading systems
"""

import numpy as np
import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any, Optional
import warnings
from scipy import stats
import json
from core.unified_enterprise_logger import get_unified_logger, ElliottWaveStep, Menu1Step, LogLevel, ProcessStatus


class EnterpriseRiskManager:
    """
    Enterprise-grade risk management system for financial trading operations
    Implements real-time risk monitoring, circuit breakers, and compliance checks
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """Initialize the enterprise risk manager"""
        self.logger = get_unified_logger()
        
        # Default risk thresholds
        self.config = config or {
            'max_position_size': 100000,  # Maximum position size
            'max_daily_loss': 5000,       # Maximum daily loss threshold
            'max_drawdown': 0.10,         # Maximum drawdown (10%)
            'volatility_threshold': 0.05,  # Volatility circuit breaker
            'outlier_threshold': 3.0,     # Z-score threshold for outliers
            'correlation_threshold': 0.95, # High correlation threshold
            'min_data_quality': 0.95,     # Minimum data quality score
            'max_leverage': 5.0,          # Maximum allowed leverage
            'risk_free_rate': 0.02        # Risk-free rate for calculations
        }
        
        # Risk monitoring state
        self.risk_state = {
            'total_exposure': 0.0,
            'daily_pnl': 0.0,
            'current_drawdown': 0.0,
            'volatility_level': 'NORMAL',
            'circuit_breaker_active': False,
            'last_risk_check': datetime.now(),
            'risk_alerts': [],
            'compliance_status': 'GREEN'
        }
        
        # Historical data for calculations
        self.price_history = []
        self.returns_history = []
        self.position_history = []
        
    def assess_data_quality_risk(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Comprehensive data quality risk assessment
        
        Args:
            data: Financial data DataFrame
            
        Returns:
            Dictionary with risk assessment results
        """
        risk_assessment = {
            'overall_score': 1.0,
            'risks_identified': [],
            'severity': 'LOW',
            'recommendations': []
        }
        
        try:
            # Missing data analysis
            missing_ratio = data.isnull().sum().sum() / (len(data) * len(data.columns))
            if missing_ratio > 0.05:
                risk_assessment['risks_identified'].append(f"High missing data: {missing_ratio:.2%}")
                risk_assessment['overall_score'] *= 0.8
                
            # Outlier detection
            numeric_cols = data.select_dtypes(include=[np.number]).columns
            outlier_risks = []
            
            for col in numeric_cols:
                if len(data[col].dropna()) > 0:
                    z_scores = np.abs(stats.zscore(data[col].dropna()))
                    outlier_count = np.sum(z_scores > self.config['outlier_threshold'])
                    outlier_ratio = outlier_count / len(data[col].dropna())
                    
                    if outlier_ratio > 0.10:  # More than 10% outliers
                        outlier_risks.append(f"{col}: {outlier_ratio:.1%}")
                        risk_assessment['overall_score'] *= 0.9
            
            if outlier_risks:
                risk_assessment['risks_identified'].append(f"High outlier presence: {', '.join(outlier_risks)}")
            
            # Data consistency checks
            if 'Open' in data.columns and 'High' in data.columns and 'Low' in data.columns and 'Close' in data.columns:
                # Check for invalid OHLC relationships
                invalid_ohlc = (
                    (data['High'] < data['Open']) | 
                    (data['High'] < data['Close']) |
                    (data['Low'] > data['Open']) | 
                    (data['Low'] > data['Close'])
                ).sum()
                
                if invalid_ohlc > 0:
                    risk_assessment['risks_identified'].append(f"Invalid OHLC relationships: {invalid_ohlc} records")
                    risk_assessment['overall_score'] *= 0.7
            
            # Determine severity
            if risk_assessment['overall_score'] >= 0.9:
                risk_assessment['severity'] = 'LOW'
            elif risk_assessment['overall_score'] >= 0.7:
                risk_assessment['severity'] = 'MEDIUM'
            else:
                risk_assessment['severity'] = 'HIGH'
                
            # Generate recommendations
            if missing_ratio > 0.01:
                risk_assessment['recommendations'].append("Implement robust data imputation strategies")
            if outlier_risks:
                risk_assessment['recommendations'].append("Deploy automated outlier detection and handling")
            if invalid_ohlc > 0:
                risk_assessment['recommendations'].append("Add data validation checks in ingestion pipeline")
                
        except Exception as e:
            self.logger.error(f"Error in data quality assessment: {str(e)}")
            risk_assessment['risks_identified'].append(f"Assessment error: {str(e)}")
            risk_assessment['severity'] = 'HIGH'
            
        return risk_assessment
    
    def calculate_var(self, returns: np.ndarray, confidence_level: float = 0.95) -> float:
        """
        Calculate Value at Risk (VaR) using historical simulation
        
        Args:
            returns: Array of historical returns
            confidence_level: Confidence level for VaR calculation
            
        Returns:
            VaR value
        """
        try:
            if len(returns) < 30:  # Need sufficient data
                return 0.0
                
            sorted_returns = np.sort(returns)
            index = int((1 - confidence_level) * len(sorted_returns))
            var = sorted_returns[index]
            
            return abs(var)
            
        except Exception as e:
            self.logger.error(f"Error calculating VaR: {str(e)}")
            return 0.0
    
    def calculate_expected_shortfall(self, returns: np.ndarray, confidence_level: float = 0.95) -> float:
        """
        Calculate Expected Shortfall (Conditional VaR)
        
        Args:
            returns: Array of historical returns
            confidence_level: Confidence level for ES calculation
            
        Returns:
            Expected Shortfall value
        """
        try:
            var = self.calculate_var(returns, confidence_level)
            tail_returns = returns[returns <= -var]
            
            if len(tail_returns) > 0:
                return abs(np.mean(tail_returns))
            else:
                return var
                
        except Exception as e:
            self.logger.error(f"Error calculating Expected Shortfall: {str(e)}")
            return 0.0
    
    def assess_market_regime_risk(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Assess risks based on current market regime
        
        Args:
            data: Financial data with market regime information
            
        Returns:
            Market regime risk assessment
        """
        regime_assessment = {
            'current_regime': 'UNKNOWN',
            'risk_level': 'MEDIUM',
            'recommendations': [],
            'volatility_forecast': 0.0
        }
        
        try:
            if 'Market_Regime' in data.columns:
                # Get most recent regime
                recent_data = data.tail(1000)  # Last 1000 observations
                regime_counts = recent_data['Market_Regime'].value_counts()
                
                if len(regime_counts) > 0:
                    regime_assessment['current_regime'] = regime_counts.index[0]
                    
                    # Assess risk based on regime
                    if regime_assessment['current_regime'] == 'High Volatility':
                        regime_assessment['risk_level'] = 'HIGH'
                        regime_assessment['recommendations'].extend([
                            "Reduce position sizes due to high volatility",
                            "Implement tighter stop-losses",
                            "Increase monitoring frequency"
                        ])
                    elif regime_assessment['current_regime'] == 'Low Volatility':
                        regime_assessment['risk_level'] = 'LOW'
                        regime_assessment['recommendations'].extend([
                            "Normal position sizes acceptable",
                            "Monitor for regime changes"
                        ])
                    else:  # Normal Volatility
                        regime_assessment['risk_level'] = 'MEDIUM'
                        regime_assessment['recommendations'].append("Standard risk management protocols")
            
            # Calculate volatility forecast
            if 'Volatility' in data.columns:
                recent_vol = data['Volatility'].tail(100).mean()
                regime_assessment['volatility_forecast'] = recent_vol
                
        except Exception as e:
            self.logger.error(f"Error in market regime assessment: {str(e)}")
            
        return regime_assessment
    
    def check_circuit_breakers(self, current_price: float, current_position: float) -> Dict[str, Any]:
        """
        Check if circuit breakers should be triggered
        
        Args:
            current_price: Current market price
            current_position: Current position size
            
        Returns:
            Circuit breaker status and actions
        """
        circuit_status = {
            'breakers_triggered': [],
            'actions_required': [],
            'trading_halted': False,
            'severity': 'NONE'
        }
        
        try:
            # Update price history
            self.price_history.append(current_price)
            if len(self.price_history) > 1000:  # Keep last 1000 prices
                self.price_history = self.price_history[-1000:]
            
            # Calculate current returns if we have price history
            if len(self.price_history) >= 2:
                current_return = (current_price - self.price_history[-2]) / self.price_history[-2]
                self.returns_history.append(current_return)
                
                if len(self.returns_history) > 1000:
                    self.returns_history = self.returns_history[-1000:]
            
            # Position size circuit breaker
            if abs(current_position) > self.config['max_position_size']:
                circuit_status['breakers_triggered'].append('POSITION_SIZE')
                circuit_status['actions_required'].append('Reduce position size immediately')
                circuit_status['severity'] = 'HIGH'
            
            # Volatility circuit breaker
            if len(self.returns_history) >= 20:
                recent_volatility = np.std(self.returns_history[-20:])
                if recent_volatility > self.config['volatility_threshold']:
                    circuit_status['breakers_triggered'].append('HIGH_VOLATILITY')
                    circuit_status['actions_required'].append('Reduce trading activity')
                    circuit_status['severity'] = 'MEDIUM'
            
            # Drawdown circuit breaker
            if len(self.price_history) >= 2:
                peak = max(self.price_history)
                current_drawdown = (peak - current_price) / peak
                
                if current_drawdown > self.config['max_drawdown']:
                    circuit_status['breakers_triggered'].append('MAX_DRAWDOWN')
                    circuit_status['actions_required'].append('Stop all trading activity')
                    circuit_status['trading_halted'] = True
                    circuit_status['severity'] = 'CRITICAL'
            
            # Update risk state
            self.risk_state['circuit_breaker_active'] = len(circuit_status['breakers_triggered']) > 0
            self.risk_state['last_risk_check'] = datetime.now()
            
        except Exception as e:
            self.logger.error(f"Error checking circuit breakers: {str(e)}")
            circuit_status['actions_required'].append(f"Circuit breaker error: {str(e)}")
            
        return circuit_status
    
    def generate_risk_report(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Generate comprehensive enterprise risk report
        
        Args:
            data: Financial data for analysis
            
        Returns:
            Comprehensive risk report
        """
        risk_report = {
            'timestamp': datetime.now().isoformat(),
            'overall_risk_score': 0.0,
            'risk_level': 'UNKNOWN',
            'data_quality': {},
            'market_regime': {},
            'circuit_breakers': {},
            'recommendations': [],
            'compliance_status': 'UNKNOWN'
        }
        
        try:
            # Data quality assessment
            risk_report['data_quality'] = self.assess_data_quality_risk(data)
            
            # Market regime assessment
            risk_report['market_regime'] = self.assess_market_regime_risk(data)
            
            # Circuit breaker status (using latest data)
            if len(data) > 0:
                latest_price = data['Close'].iloc[-1] if 'Close' in data.columns else 0.0
                risk_report['circuit_breakers'] = self.check_circuit_breakers(latest_price, 0.0)
            
            # Calculate overall risk score
            data_quality_score = risk_report['data_quality']['overall_score']
            
            regime_risk_multiplier = {
                'LOW': 1.0,
                'MEDIUM': 0.8,
                'HIGH': 0.6
            }.get(risk_report['market_regime']['risk_level'], 0.7)
            
            circuit_breaker_penalty = 0.5 if risk_report['circuit_breakers'].get('trading_halted', False) else 1.0
            
            risk_report['overall_risk_score'] = data_quality_score * regime_risk_multiplier * circuit_breaker_penalty
            
            # Determine risk level
            if risk_report['overall_risk_score'] >= 0.8:
                risk_report['risk_level'] = 'LOW'
                risk_report['compliance_status'] = 'GREEN'
            elif risk_report['overall_risk_score'] >= 0.6:
                risk_report['risk_level'] = 'MEDIUM'
                risk_report['compliance_status'] = 'YELLOW'
            else:
                risk_report['risk_level'] = 'HIGH'
                risk_report['compliance_status'] = 'RED'
            
            # Aggregate recommendations
            risk_report['recommendations'].extend(risk_report['data_quality'].get('recommendations', []))
            risk_report['recommendations'].extend(risk_report['market_regime'].get('recommendations', []))
            risk_report['recommendations'].extend(risk_report['circuit_breakers'].get('actions_required', []))
            
            # Add enterprise-specific recommendations
            if risk_report['risk_level'] == 'HIGH':
                risk_report['recommendations'].extend([
                    "Implement enhanced monitoring and reporting",
                    "Review and update risk management procedures",
                    "Consider temporary reduction in trading activity"
                ])
            
        except Exception as e:
            self.logger.error(f"Error generating risk report: {str(e)}")
            risk_report['risk_level'] = 'HIGH'
            risk_report['compliance_status'] = 'RED'
            risk_report['recommendations'].append(f"Risk assessment error: {str(e)}")
        
        return risk_report
    
    def export_risk_report(self, risk_report: Dict[str, Any], filepath: str) -> bool:
        """
        Export risk report to JSON file
        
        Args:
            risk_report: Risk report dictionary
            filepath: Path to save the report
            
        Returns:
            Success status
        """
        try:
            with open(filepath, 'w') as f:
                json.dump(risk_report, f, indent=2, default=str)
            
            self.logger.info(f"Risk report exported to {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error exporting risk report: {str(e)}")
            return False

# Example usage and testing
if __name__ == "__main__":
    # Create risk manager instance
    risk_manager = EnterpriseRiskManager()
    
    # Example data for testing
    test_data = pd.DataFrame({
        'Open': np.random.normal(2000, 100, 1000),
        'High': np.random.normal(2005, 100, 1000),
        'Low': np.random.normal(1995, 100, 1000),
        'Close': np.random.normal(2000, 100, 1000),
        'Volume': np.random.exponential(0.05, 1000),
        'Market_Regime': np.random.choice(['Low Volatility', 'Normal Volatility', 'High Volatility'], 1000)
    })
    
    # Generate risk report
    report = risk_manager.generate_risk_report(test_data)
    
    print("üõ°Ô∏è ENTERPRISE RISK MANAGEMENT REPORT")
    print("=" * 50)
    print(f"Risk Level: {report['risk_level']}")
    print(f"Compliance Status: {report['compliance_status']}")
    print(f"Overall Risk Score: {report['overall_risk_score']:.3f}")
    print(f"Data Quality Score: {report['data_quality']['overall_score']:.3f}")
    print(f"Market Regime: {report['market_regime']['current_regime']}")
    print(f"Recommendations: {len(report['recommendations'])}")
    
    for i, rec in enumerate(report['recommendations'][:5], 1):
        print(f"  {i}. {rec}")
