# -*- coding: utf-8 -*-
"""
/content/drive/MyDrive/ProjectP-1/core/enterprise_data_validator.py

## üõ°Ô∏è NICEGOLD Enterprise ProjectP - Enterprise Data Validator

**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 1.0
**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:** Production Ready
**‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï:** 9 ‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏° 2025
**‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤:** NICEGOLD AI Agent (AgentP)
**‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠:** enterprise.nicegold.ai@nicegold.com

### üìù **‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î**
‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏î‡∏±‡∏ö Enterprise ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NICEGOLD ProjectP 
‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Integrity) ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Pipeline ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI

### ‚ú® **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏•‡∏±‡∏Å (Key Features)**
- **Robust Type Enforcement:** ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏•‡∏±‡∏Å (OHLCV) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î
- **Error Coercion:** ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô `NaN` (Not a Number) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ
- **Missing Value Handling:** ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Missing Values)
- **Detailed Logging:** ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡πà‡∏≤‡∏ô Unified Enterprise Logger
- **Pre-computation Validation:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Noise Filtering ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô `TypeError`

### üèóÔ∏è **‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°**
- **Class EnterpriseDataValidator:** ‡∏Ñ‡∏•‡∏≤‡∏™‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
- **Integration:** ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö `ElliottWaveDataProcessor` ‡πÅ‡∏•‡∏∞ `UnifiedEnterpriseLogger`
- **Stateless Design:** ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤

### üéØ **‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**
- **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ `TypeError`:** ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡πâ‡∏ô‡∏ï‡∏≠‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ `'<' not supported between instances of 'str' and 'int'` 
  ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
- **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á Pipeline:** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Pipeline ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- **‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö

---
"""

import pandas as pd
from typing import Optional

class EnterpriseDataValidator:
    """
    A robust, enterprise-grade validator for financial time-series data.
    Ensures data integrity, correct data types, and handles inconsistencies
    before the data is used in any analytical or ML pipeline.
    """
    def __init__(self, logger):
        """
        Initializes the validator with a logger instance.

        Args:
            logger: An instance of the UnifiedEnterpriseLogger for detailed logging.
        """
        self.logger = logger
        self.component_name = "EnterpriseDataValidator"

    def validate_and_clean(self, df: pd.DataFrame, ohlcv_columns: list) -> Optional[pd.DataFrame]:
        """
        The main validation and cleaning pipeline.

        Args:
            df (pd.DataFrame): The input DataFrame to validate.
            ohlcv_columns (list): A list of column names for Open, High, Low, Close, Volume.

        Returns:
            Optional[pd.DataFrame]: A cleaned and validated DataFrame, or None if validation fails.
        """
        if not isinstance(df, pd.DataFrame):
            self.logger.error("Input is not a pandas DataFrame.")
            return None

        self.logger.info(f"Starting enterprise data validation and cleaning for {len(df)} rows.")
        
        initial_rows = len(df)
        
        # 1. Enforce numeric types for critical columns
        df_numeric = self._enforce_numeric_types(df.copy(), ohlcv_columns)
        if df_numeric is None:
            return None # Error already logged

        rows_after_coercion = len(df_numeric)
        if rows_after_coercion < initial_rows:
             self.logger.warning(f"{initial_rows - rows_after_coercion} rows contained non-numeric values and were marked for removal.")

        # 2. Handle missing values
        df_cleaned = self._handle_missing_values(df_numeric, ohlcv_columns)
        if df_cleaned is None:
            return None # Error already logged

        final_rows = len(df_cleaned)
        rows_dropped = initial_rows - final_rows
        
        if rows_dropped > 0:
            self.logger.warning(f"Dropped {rows_dropped} rows due to non-numeric values or missing data in critical columns.")
        
        self.logger.info(f"Data validation and cleaning complete. Final dataset has {final_rows} rows.")
        
        # Log final dtypes for verification
        self.logger.debug(f"Final dtypes:\n{df_cleaned[ohlcv_columns].dtypes.to_string()}")

        return df_cleaned

    def _enforce_numeric_types(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """
        Converts specified columns to numeric types, coercing errors to NaN.
        """
        self.logger.info(f"Enforcing numeric data types for columns: {columns}")
        
        for col in columns:
            if col in df.columns:
                if not pd.api.types.is_numeric_dtype(df[col]):
                    self.logger.info(f"Column '{col}' is not numeric. Attempting conversion.")
                    original_non_numeric = df[col].apply(type).ne(int).ne(float).sum()
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    self.logger.info(f"Converted '{col}' to numeric. {original_non_numeric} values were non-numeric.")
                else:
                    self.logger.debug(f"Column '{col}' is already numeric.")
            else:
                self.logger.warning(f"Column '{col}' not found in DataFrame. Skipping type enforcement.")
        
        return df

    def _handle_missing_values(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """
        Detects and removes rows with NaN values in the specified critical columns.
        """
        self.logger.info("Checking for missing values in critical columns...")
        
        initial_rows = len(df)
        
        # Drop rows where any of the critical columns are NaN
        df.dropna(subset=columns, inplace=True)
        
        rows_after_dropna = len(df)
        rows_dropped = initial_rows - rows_after_dropna
        
        if rows_dropped > 0:
            self.logger.warning(f"Removed {rows_dropped} rows with missing data in columns: {columns}")
        else:
            self.logger.info("No missing values found in critical columns.")
            
        return df
